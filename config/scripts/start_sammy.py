#!/usr/bin/env python3
"""
Sammy AI Hebrew Summarizer - Startup Script
One-command startup for the complete AI system
"""

import subprocess
import sys
import time
import requests
from pathlib import Path

def check_dependencies():
    """Check if required packages are installed."""
    required_packages = [
        'torch', 'transformers', 'flask', 'flask_cors', 
        'numpy', 'sklearn', 'networkx'
    ]
    
    missing = []
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
        except ImportError:
            missing.append(package)
    
    if missing:
        print(f"âŒ Missing packages: {', '.join(missing)}")
        print("Install with: pip install -r backend/requirements.txt")
        return False
    
    print("âœ… All dependencies installed")
    return True

def preload_models():
    """Preload AI models if not already cached."""
    print("ğŸ¤– Checking AI models...")
    
    try:
        # Quick test to see if models are cached
        from transformers import AutoTokenizer
        tokenizer = AutoTokenizer.from_pretrained('onlplab/alephbert-base')
        print("âœ… AlephBERT model cached")
        
        tokenizer = AutoTokenizer.from_pretrained('Dicta-IL/dictalm2.0')
        print("âœ… Dicta Hebrew model cached")
        
        return True
        
    except Exception as e:
        print("ğŸ“¥ Models not cached, downloading...")
        result = subprocess.run([sys.executable, 'preload_models.py'], 
                              capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… Models downloaded successfully")
            return True
        else:
            print(f"âŒ Model download failed: {result.stderr}")
            return False

def start_ai_server():
    """Start the AI server."""
    print("ğŸš€ Starting AI server...")
    
    # Start server in background
    process = subprocess.Popen([
        sys.executable, 'backend/ai_server.py'
    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    
    # Wait for server to start
    for i in range(30):  # Wait up to 30 seconds
        try:
            response = requests.get('http://localhost:5002/health', timeout=1)
            if response.status_code == 200:
                print("âœ… AI server started successfully")
                print("ğŸ“ Server running on: http://localhost:5002")
                return process
        except:
            pass
        
        time.sleep(1)
        print(f"â³ Waiting for server... ({i+1}/30)")
    
    print("âŒ Server failed to start")
    process.terminate()
    return None

def load_models_in_server():
    """Preload models in the running server."""
    print("ğŸ§  Loading AI models in server...")
    
    try:
        response = requests.post('http://localhost:5002/load_models', timeout=60)
        if response.status_code == 200:
            print("âœ… AI models loaded in server")
            return True
        else:
            print(f"âŒ Failed to load models: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Error loading models: {e}")
        return False

def test_summarization():
    """Test both summarization methods."""
    print("ğŸ§ª Testing summarization...")
    
    test_text = """
    ×‘×™× ×” ××œ××›×•×ª×™×ª ×”×™× ×ª×—×•× ××“×¢×™ ×”××ª××—×” ×‘×¤×™×ª×•×— ××¢×¨×›×•×ª ××—×©×‘ ×”××¡×•×’×œ×•×ª ×œ×‘×¦×¢ ××©×™××•×ª ×”×“×•×¨×©×•×ª ×‘×“×¨×š ×›×œ×œ ××™× ×˜×œ×™×’× ×¦×™×” ×× ×•×©×™×ª. 
    ×”×ª×—×•× ×›×•×œ×œ ×œ××™×“×ª ××›×•× ×”, ×¢×™×‘×•×“ ×©×¤×” ×˜×‘×¢×™×ª, ×¨××™×™×” ×××•×—×©×‘×ª ×•×¢×•×“. ×‘×©× ×™× ×”××—×¨×•× ×•×ª ×—×œ×” ×”×ª×¤×ª×—×•×ª ××”×™×¨×” ×‘×ª×—×•×, 
    ×‘××™×•×—×“ ×‘×–×›×•×ª ×¨×©×ª×•×ª × ×•×™×¨×•× ×™× ×¢××•×§×•×ª. ×˜×›× ×•×œ×•×’×™×•×ª ××œ×• ××©× ×•×ª ××ª ×¤× ×™ ×”×ª×¢×©×™×™×” ×•×”×—×‘×¨×”.
    """
    
    # Test extractive
    try:
        response = requests.post('http://localhost:5002/summarize', 
                               json={'text': test_text, 'method': 'extractive'},
                               timeout=10)
        if response.status_code == 200:
            print("âœ… Extractive summarization working")
        else:
            print("âŒ Extractive summarization failed")
    except Exception as e:
        print(f"âŒ Extractive test failed: {e}")
    
    # Test abstractive
    try:
        response = requests.post('http://localhost:5002/summarize', 
                               json={'text': test_text, 'method': 'abstractive'},
                               timeout=30)
        if response.status_code == 200:
            print("âœ… Abstractive summarization working")
        else:
            print("âŒ Abstractive summarization failed")
    except Exception as e:
        print(f"âŒ Abstractive test failed: {e}")

def show_extension_instructions():
    """Show Chrome extension installation instructions."""
    print("\n" + "="*60)
    print("ğŸ‰ SAMMY AI IS READY!")
    print("="*60)
    print("\nğŸ“± Install Chrome Extension:")
    print("1. Open Chrome and go to: chrome://extensions/")
    print("2. Enable 'Developer mode' (toggle in top right)")
    print("3. Click 'Load unpacked'")
    print("4. Select the 'frontend' folder from this project")
    print("5. Extension installed! Look for Sammy icon in toolbar")
    
    print("\nğŸ§ª Test the Extension:")
    print("1. Open test_extension.html in Chrome")
    print("2. Click the Sammy extension icon")
    print("3. Choose summarization method:")
    print("   â€¢ ×—×™×œ×•×¥ ×—×›× (Extractive) - Fast, reliable")
    print("   â€¢ ×™×¦×™×¨×” ×—×“×©×” (Abstractive) - Creative, slower")
    print("4. Click '×¡×›× ×“×£' and see the magic!")
    
    print("\nğŸŒ Use on Real Websites:")
    print("Visit any Hebrew website (Ynet, Haaretz, etc.) and summarize!")
    
    print(f"\nğŸ”§ Server Status:")
    print(f"â€¢ AI Server: http://localhost:5002")
    print(f"â€¢ Models: AlephBERT + mT5 loaded")
    print(f"â€¢ Methods: Extractive & Abstractive ready")
    
    print(f"\nâ¹ï¸  To stop: Press Ctrl+C")

def main():
    """Main startup function."""
    print("ğŸ¤– SAMMY AI HEBREW SUMMARIZER")
    print("=" * 50)
    
    # Check dependencies
    if not check_dependencies():
        return
    
    # Preload models
    if not preload_models():
        return
    
    # Start server
    server_process = start_ai_server()
    if not server_process:
        return
    
    # Load models in server
    if not load_models_in_server():
        server_process.terminate()
        return
    
    # Test functionality
    test_summarization()
    
    # Show instructions
    show_extension_instructions()
    
    # Keep server running
    try:
        server_process.wait()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Shutting down Sammy AI...")
        server_process.terminate()
        print("âœ… Server stopped")

if __name__ == "__main__":
    main()